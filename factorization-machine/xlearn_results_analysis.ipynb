{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Quick Practice] \n",
    "-----\n",
    "-----\n",
    "## Post-Analysis Process - Factorization Machine\n",
    "#### Using xlearn python-wrapper module (https://xlearn-doc.readthedocs.io/en/latest/)\n",
    "\n",
    "- Using Titanic dataset. (https://www.kaggle.com/c/titanic)\n",
    "- Original paper (Steffen Rendle, https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "- Basic Conceptual Description for FM in korean (http://yamalab.tistory.com/107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## Step 1 : prepare FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_path = \"./dataset/titanic_dataset.csv\"\n",
    "df2_path = \"./dataset/titanic_answer.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(df1_path)\n",
    "df2 = pd.read_csv(df2_path)\n",
    "df = df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_discretize(x):\n",
    "    if x == np.nan:\n",
    "        return '10'\n",
    "    else:\n",
    "        x = int(x)\n",
    "        if x < 10:\n",
    "            return '1'\n",
    "        elif x < 20 and x >= 10:\n",
    "            return '2'\n",
    "        elif x < 30 and x >= 20:\n",
    "            return '3'\n",
    "        elif x < 40 and x >= 30:\n",
    "            return '4'\n",
    "        elif x < 50 and x >= 40:\n",
    "            return '5'\n",
    "        elif x < 60 and x >= 50:\n",
    "            return '6'\n",
    "        elif x < 70 and x >= 60:\n",
    "            return '7'\n",
    "        elif x < 80 and x >= 70:\n",
    "            return '8'\n",
    "        elif x < 90 and x >= 80:\n",
    "            return '9'\n",
    "        else:\n",
    "            return '10'\n",
    "\n",
    "def fare_discretize(x):\n",
    "    if x < 10:\n",
    "        return '1'\n",
    "    elif x < 20 and x >= 10:\n",
    "        return '2'\n",
    "    elif x < 30 and x >= 20:\n",
    "        return '3'\n",
    "    elif x < 40 and x >= 30:\n",
    "        return '4'\n",
    "    elif x < 50 and x >= 40:\n",
    "        return '5'\n",
    "    elif x < 60 and x >= 50:\n",
    "        return '6'\n",
    "    elif x < 70 and x >= 60:\n",
    "        return '7'\n",
    "    elif x < 80 and x >= 70:\n",
    "        return '8'\n",
    "    elif x < 90 and x >= 80:\n",
    "        return '9'\n",
    "    else:\n",
    "        return '10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "df = df.dropna()\n",
    "\n",
    "df['sex'] = df['sex'].apply(lambda x: '1' if x == \"female\" else '0')\n",
    "df['age'] = df['age'].apply(lambda x: age_discretize(x))\n",
    "df['fare'] = df['fare'].apply(lambda x: fare_discretize(int(x)))\n",
    "\n",
    "df['survived'] = df['survived'].astype('str')\n",
    "df['pclass'] = df['pclass'].astype('str')\n",
    "df['sibsp'] = df['sibsp'].astype('str')\n",
    "df['parch'] = df['parch'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make discretized label to 1~n dict\n",
    "def make_encoding_label_dict(col_unique):\n",
    "    encoded_dict = {}\n",
    "    for idx, unique in enumerate(col_unique):\n",
    "        encoded_dict[unique] = idx + 1\n",
    "\n",
    "    return encoded_dict\n",
    "\n",
    "\n",
    "# get new encoding result\n",
    "def get_newcode(key, label_dict):\n",
    "    com_len = len(label_dict)\n",
    "    if key == np.nan:\n",
    "        return\n",
    "    else:\n",
    "        if key in label_dict:\n",
    "            return label_dict[key]\n",
    "        else:\n",
    "            return com_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sibsp_dict = make_encoding_label_dict(df.sibsp.value_counts().index.tolist())\n",
    "encoded_parch_dict = make_encoding_label_dict(df.parch.value_counts().index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sibsp'] = df['sibsp'].apply(lambda x: get_newcode(x, encoded_sibsp_dict))\n",
    "df['parch'] = df['parch'].apply(lambda x: get_newcode(x, encoded_parch_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_len_dict = {'pclass': 3, 'sex': 1, 'age': 9, 'sibsp': 7, 'parch': 7, 'fare': 10}\n",
    "col_accum_index_dict = {}\n",
    "cumulative = 0\n",
    "for key, value in col_len_dict.items():\n",
    "    col_accum_index_dict[key] = cumulative\n",
    "    cumulative = cumulative + value\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open('./dataset/train.txt', 'w')\n",
    "for idx, row in train_df.iterrows():\n",
    "    vec = []\n",
    "    label = row['survived']\n",
    "    vec.append(str(label))\n",
    "    row = row.drop(labels=['survived'])\n",
    "    for key, value in row.items():\n",
    "        if col_len_dict[key] == 1:\n",
    "            if value != '0':\n",
    "                col_idx = col_accum_index_dict[key]\n",
    "                out_val = value\n",
    "                vec.append(str(col_idx) + \":\" + str(out_val))\n",
    "        else:\n",
    "            col_idx = col_accum_index_dict[key] + (int(value) - 1)\n",
    "            out_val = 1\n",
    "            vec.append(str(col_idx) + \":\" + str(out_val))\n",
    "    txt_file.write(\"%s\\n\" % \" \".join(vec))\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open('./dataset/test.txt', 'w')\n",
    "for idx, row in test_df.iterrows():\n",
    "    vec = []\n",
    "    label = row['survived']\n",
    "    vec.append(str(label))\n",
    "    row = row.drop(labels=['survived'])\n",
    "    for key, value in row.items():\n",
    "        if col_len_dict[key] == 1:\n",
    "            if value != '0':\n",
    "                col_idx = col_accum_index_dict[key]\n",
    "                out_val = value\n",
    "                vec.append(str(col_idx) + \":\" + str(out_val))\n",
    "        else:\n",
    "            col_idx = col_accum_index_dict[key] + (int(value) - 1)\n",
    "            out_val = 1\n",
    "            vec.append(str(col_idx) + \":\" + str(out_val))\n",
    "    txt_file.write(\"%s\\n\" % \" \".join(vec))\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## Step 2 : learn FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlearn as xl\n",
    "\n",
    "def runner():\n",
    "    fm_model = xl.create_fm()\n",
    "\n",
    "    train_path = './dataset/train.txt'\n",
    "    test_path = './dataset/test.txt'\n",
    "\n",
    "    fm_model.setTrain(train_path)\n",
    "    fm_model.setValidate(test_path)\n",
    "\n",
    "    # Parameters:\n",
    "    param = {'task':'binary',\n",
    "             'epoch': 10,\n",
    "             'lr': 0.2,\n",
    "             'lambda': 0.002,\n",
    "             'metric': 'auc'}\n",
    "\n",
    "    # Start to train : fit이 seTXTModel 보다 뒤에 있어야만 model.txt가 생성됨.\n",
    "    fm_model.setTXTModel('./model.txt')\n",
    "    fm_model.fit(param, './model.out')\n",
    "\n",
    "    # Prediction task\n",
    "    fm_model.setTest(test_path)\n",
    "    fm_model.setSigmoid()\n",
    "\n",
    "    # Start to predict\n",
    "    fm_model.predict(\"./model.out\", \"./output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "## Step 3 : Analyze FM's vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1342b89c38a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mv_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "txt_path = './model.txt'\n",
    "\n",
    "w = list()\n",
    "v = list()\n",
    "with open(txt_path, 'r') as my_file:\n",
    "    lines = my_file.readlines()\n",
    "    for line in lines:\n",
    "        cut_line = line.strip().split(' ')\n",
    "        if len(cut_line) == 1:\n",
    "            w.append(cut_line[0])\n",
    "        elif len(cut_line) > 1:\n",
    "            v.append(cut_line)\n",
    "\n",
    "w = np.array(w).astype(np.float)\n",
    "v = np.array(v).astype(np.float)\n",
    "\n",
    "v_r = np.array(v).astype(np.float).ravel()\n",
    "v_ij = np.matmul(v, v.T).ravel()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
